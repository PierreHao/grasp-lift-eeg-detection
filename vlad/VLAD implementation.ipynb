{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VLAD implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib nbagg\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.datasets import make_blobs\n",
    "from sklearn.metrics.pairwise import pairwise_distances\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Kmeans++"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def getPermutation(totalRange,numberElements):\n",
    "    random_seed = 10312003\n",
    "    rng = np.random.RandomState(random_seed)\n",
    "    permutation = rng.permutation(totalRange)\n",
    "    return permutation[:numberElements]\n",
    "\n",
    "\n",
    "def mykmeans_plus_plus(X, max_clusters = 8, max_iterations=1000):\n",
    "    randState = 10312003\n",
    "    rnd = np.random.RandomState(randState)\n",
    "    centroids=generateStartingCentroid(X,max_clusters)\n",
    "    minInertia = 0\n",
    "    inertia = 0\n",
    "    for nIter in range(0, max_iterations):\n",
    "        distances = pairwise_distances(X, centroids, metric='euclidean')\n",
    "        clusters = np.argmin(distances,axis=1)\n",
    "        min_distances = np.amin(distances, axis=1)\n",
    "        sum_distortion = min_distances.sum()\n",
    "        inertia = np.sum(np.amin(distances, axis=1))  \n",
    "        if (minInertia ==0 or inertia < minInertia):\n",
    "            minInertia = inertia\n",
    "            notImproveCount=0\n",
    "        elif minInertia !=0 and inertia >= minInertia:\n",
    "            notImproveCount+=1\n",
    "        if (notImproveCount>10):\n",
    "            print(\"iteration: \", nIter, \" inertia: \",inertia, \" minInertia: \",minInertia)\n",
    "            break\n",
    "        data = np.concatenate([X, clusters[:,np.newaxis]], axis=1)\n",
    "        for cRange in range(0,max_clusters):\n",
    "            allpoints = data[np.where(data[:,(data.shape[1] - 1)] == cRange)][:,range(0, data.shape[1] -1)]\n",
    "            centroids[cRange] = np.sum(allpoints, axis=0)/allpoints.shape[0]\n",
    "    return centroids\n",
    "\n",
    "\n",
    "def generateStartingCentroid(X,maxClusternumbers):\n",
    "    nPoint,dimension = X.shape\n",
    "    centroids=np.zeros([maxClusternumbers,dimension])\n",
    "    getPermutation\n",
    "    randState = 10312003\n",
    "    rnd = np.random.RandomState(randState)\n",
    "    centroids[0] = X[rnd.permutation(len(X))[0]]\n",
    "    for i in (range(1,maxClusternumbers)):\n",
    "        distances = pairwise_distances(X, centroids[:i], metric='euclidean')\n",
    "        d2weighting=np.power(np.min(distances,axis=1),2)\n",
    "        d2weighting = d2weighting/np.sum(d2weighting)\n",
    "        allIndex = range(len(X))\n",
    "        index = np.random.choice(allIndex, p=d2weighting)\n",
    "        centroids[i]=X[index]\n",
    "    return centroids"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### My-Vlad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    We have a two dimensional sample which has to be represented using the vocabulary described by K centroids.\n",
    "    The algorithm goes over each and every entry in \n",
    "\"\"\"\n",
    "\n",
    "# vocabulary defined by k centroids\n",
    "# sample has dimension defined by (n,d)\n",
    "def my_vlad(local_descriptors, centroids):\n",
    "    V = np.zeros([centroids.shape[0],local_descriptors.shape[1]])\n",
    "    distances = pairwise_distances(local_descriptors, centroids, metric='euclidean')\n",
    "    clusters = np.argmin(distances,axis=1)\n",
    "    for iter, center in enumerate(centroids):\n",
    "        points_belonging_to_cluster = local_descriptors[clusters == iter]\n",
    "        V[iter] = np.sum(points_belonging_to_cluster - center, axis=0)\n",
    "        \n",
    "    return V"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('iteration: ', 12, ' inertia: ', 2780.9452838688244, ' minInertia: ', 2780.9452838688244)\n"
     ]
    }
   ],
   "source": [
    "X_train,y_train = make_blobs(n_samples=500, n_features=32, centers=8)\n",
    "\n",
    "X_val, y_val = make_blobs(n_samples=40, n_features=32, centers=8)\n",
    "\n",
    "centroids = mykmeans_plus_plus(X_train)\n",
    "\n",
    "vlad = my_vlad(X_train, centroids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8, 32)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vlad.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
